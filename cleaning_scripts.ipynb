{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5e431236",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "#Import\n",
    "import os\n",
    "from scipy import stats\n",
    "from env import username, host, password \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97e9fdac",
   "metadata": {},
   "source": [
    "A. Steps for cleaning data\n",
    " 1. df.info()\n",
    " 2. This identifies numerics and non numerics \n",
    " cat_df = airbnb.select_dtypes(include=['object'])\n",
    "    num_df = airbnb.select_dtypes(exclude=['object'])\n",
    "\n",
    "    def printColumnTypes(non_numeric_df, numeric_df):\n",
    "    '''separates non-numeric and numeric columns'''\n",
    "    print(\"Non-Numeric columns:\")\n",
    "    for col in non_numeric_df:\n",
    "        print(f\"{col}\")\n",
    "    print(\"\")\n",
    "    print(\"Numeric columns:\")\n",
    "    for col in numeric_df:\n",
    "        print(f\"{col}\")\n",
    "        \n",
    "    printColumnTypes(cat_df, num_df)\n",
    " 3. Identify nulls\n",
    "     df.isnull().sum()\n",
    " 4. Identify percent missing\n",
    "     def perc_missing(df):\n",
    "    '''prints out columns with missing values with its %'''\n",
    "    for col in df.columns:\n",
    "        pct = df[col].isna().mean() * 100\n",
    "        if (pct != 0):\n",
    "            print('{} => {}%'.format(col, round(pct, 2)))\n",
    "    \n",
    "    perc_missing(airbnb)\n",
    " 5. Options when dealing with missing values\n",
    "     1. Drop the feature\n",
    "     2. Drop the row\n",
    "     3. Impute the missing value\n",
    "     4. Replace it\n",
    " 6. _# Drop unnecessary columns that are not important\n",
    "    colsToDrop = ['id','host_name','last_review']\n",
    "\n",
    "    airbnb.drop(colsToDrop, axis=1, inplace=True)\n",
    "\n",
    "    missing_cols(airbnb)\n",
    "  7. # imputing price with mean\n",
    "price_mean_value = round(airbnb['price'].mean(), 2)\n",
    "airbnb['price'].fillna(price_mean_value, inplace=True)\n",
    "\n",
    "# imputing price with median\n",
    "price_median_value = round(airbnb['price'].median(), 2)\n",
    "airbnb['price'].fillna(price_median_value, inplace=True)\n",
    "\n",
    "# imputing with bfill or ffill\n",
    "airbnb['price'].bfill(inplace=True)\n",
    "airbnb['price'].ffill(inplace=True)\n",
    "\n",
    "# imputing with SimpleImputor from the sklearn library\n",
    "from sklearn.impute import SimpleImputer\n",
    "# define the imputer\n",
    "imr = SimpleImputer(missing_values=np.nan, strategy='mean') # or median\n",
    "\n",
    "airbnb[['price']] = imr.fit_transform(airbnb[['price']])\n",
    "\n",
    "# use strategy = 'most_frequent' for categorical data\n",
    "\n",
    "8. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "69c3f946",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-e10131f7512c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# select numerical columns\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mdf_numeric\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mselect_dtypes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minclude\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumber\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mnumeric_cols\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf_numeric\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# select non-numeric columns\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mdf_non_numeric\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mselect_dtypes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexclude\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumber\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'df' is not defined"
     ]
    }
   ],
   "source": [
    "# select numerical columns\n",
    "df_numeric = df.select_dtypes(include=[np.number])\n",
    "numeric_cols = df_numeric.columns.values\n",
    "# select non-numeric columns\n",
    "df_non_numeric = df.select_dtypes(exclude=[np.number])\n",
    "non_numeric_cols = df_non_numeric.columns.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0deac4f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def summarize_df(df):\n",
    "    print('-----Head-------')\n",
    "    print(df.head(3))\n",
    "    print('-----shape------')\n",
    "    print('{} rows and {} columns'.format(df.shape[0], df.shape[1]))\n",
    "    print('---info---')\n",
    "    print(df.info())\n",
    "    print(df.describe())\n",
    "    print('----Catagorical Variables----')\n",
    "    print(df.select_dtypes(include='object').columns.tolist())\n",
    "    print('----Continous  Variables----')\n",
    "    print(df.select_dtypes(exclude='object').columns.tolist())\n",
    "    print('--nulls--')\n",
    "    num_cols = [col for col in df.columns if df[col].dtype != 'O']\n",
    "    cat_cols = [col for col in df.columns if col not in num_cols]\n",
    "    print('=====================================================')\n",
    "    for col in df.columns:\n",
    "        if col in cat_cols:\n",
    "            print(df[col].value_counts())\n",
    "        else:\n",
    "            print(df[col].value_counts(bins=10, sort=False))\n",
    "    print('=====================================================')\n",
    "    df = df.replace(r'^\\s*$', np.NaN, regex=True)\n",
    "    print(df.isna().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "45215ab7",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-ee0f1566e9f9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mvalues_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mcols_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mcol\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[0mpct_missing\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcol\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misnull\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mcols_list\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcol\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'df' is not defined"
     ]
    }
   ],
   "source": [
    "# % of values missing in each column\n",
    "values_list = list()\n",
    "cols_list = list()\n",
    "for col in df.columns:\n",
    "    pct_missing = np.mean(df[col].isnull())*100\n",
    "    cols_list.append(col)\n",
    "    values_list.append(pct_missing)\n",
    "pct_missing_df = pd.DataFrame()\n",
    "pct_missing_df['col'] = cols_list\n",
    "pct_missing_df['pct_missing'] = values_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7491f45e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def nulls_by_col(df):\n",
    "    num_missing = df.isnull().sum()\n",
    "    print(type(num_missing))\n",
    "    rows = df.shape[0]\n",
    "    prcnt_miss = num_missing / rows * 100\n",
    "    cols_missing = pd.DataFrame({'num_rows_missing': num_missing, 'percent_rows_missing': prcnt_miss})\n",
    "    return cols_missing\n",
    "\n",
    "def nulls_by_row(df):\n",
    "    num_missing = df.isnull().sum(axis=1)\n",
    "    prcnt_miss = num_missing / df.shape[1] * 100\n",
    "    rows_missing = pd.DataFrame({'num_cols_missing': num_missing, 'percent_cols_missing': prcnt_miss})\\\n",
    "    .reset_index()\\\n",
    "    .groupby(['num_cols_missing', 'percent_cols_missing']).count()\\\n",
    "    .rename(index=str, columns={'index': 'num_rows'}).reset_index()\n",
    "    return rows_missing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9ae40224",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pct_missing_df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-75971eb0e91d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# plots showing missing values\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mpct_missing_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpct_missing_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpct_missing\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkind\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'bar'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfigsize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m12\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m8\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'pct_missing_df' is not defined"
     ]
    }
   ],
   "source": [
    "# plots showing missing values\n",
    "pct_missing_df.loc[pct_missing_df.pct_missing > 0].plot(kind='bar', figsize=(12,8))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "595b47ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dropping dupes\n",
    "df = df.drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8aecc67c",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pct_missing_df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-0ba97cafc7fc>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# drops columns which over 50% values contains nulls\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mless_missing_values_cols_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpct_missing_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpct_missing_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpct_missing\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m0.5\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m&\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mpct_missing_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpct_missing\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'col'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropna\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msubset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mless_missing_values_cols_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minplace\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'pct_missing_df' is not defined"
     ]
    }
   ],
   "source": [
    "# drops observations which over 50% values contains nulls\n",
    "less_missing_values_cols_list = list(pct_missing_df.loc[(pct_missing_df.pct_missing < 0.5) & (pct_missing_df.pct_missing > 0), 'col'].values)\n",
    "df.dropna(subset=less_missing_values_cols_list, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1dd57a11",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pct_missing_df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-ed9ee6d9c423>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# dropping columns with more than 40% null values\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0m_40_pct_missing_cols_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpct_missing_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpct_missing_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpct_missing\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m40\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'col'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0m_40_pct_missing_cols_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minplace\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'pct_missing_df' is not defined"
     ]
    }
   ],
   "source": [
    "# dropping columns with more than 40% null values\n",
    "_40_pct_missing_cols_list = list(pct_missing_df.loc[pct_missing_df.pct_missing > 40, 'col'].values)\n",
    "df.drop(columns=_40_pct_missing_cols_list, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b26f09d3",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-1196dd3313f5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# imputes nulls in columns with the median\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mdf_numeric\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mselect_dtypes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minclude\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumber\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mnumeric_cols\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf_numeric\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mcol\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mnumeric_cols\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mmissing\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcol\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misnull\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'df' is not defined"
     ]
    }
   ],
   "source": [
    "# imputes nulls in numerical columns with the median\n",
    "df_numeric = df.select_dtypes(include=[np.number])\n",
    "numeric_cols = df_numeric.columns.values\n",
    "for col in numeric_cols:\n",
    "    missing = df[col].isnull()\n",
    "    num_missing = np.sum(missing)\n",
    "    if num_missing > 0:  # impute values only for columns that have missing values\n",
    "        med = df[col].median() #impute with the median\n",
    "        df[col] = df[col].fillna(med)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "48322294",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-342a79b29046>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# imputes missing values of categorical columns with the mode\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mdf_non_numeric\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mselect_dtypes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexclude\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumber\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mnon_numeric_cols\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf_non_numeric\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mcol\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mnon_numeric_cols\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mmissing\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcol\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misnull\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'df' is not defined"
     ]
    }
   ],
   "source": [
    "# imputes missing values of categorical columns with the mode\n",
    "df_non_numeric = df.select_dtypes(exclude=[np.number])\n",
    "non_numeric_cols = df_non_numeric.columns.values\n",
    "for col in non_numeric_cols:\n",
    "    missing = df[col].isnull()\n",
    "    num_missing = np.sum(missing)\n",
    "    if num_missing > 0:  # impute values only for columns that have missing values\n",
    "        mod = df[col].describe()['top'] # impute with the most frequently occuring value\n",
    "        df[col] = df[col].fillna(mod)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bd7229c1",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-b6c6e2b80569>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# dropping duplicates by considering all columns other than ID\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mcols_other_than_id\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop_duplicates\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msubset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcols_other_than_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minplace\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'df' is not defined"
     ]
    }
   ],
   "source": [
    "# dropping duplicates by considering all columns other than ID\n",
    "cols_other_than_id = list(df.columns)[1:]\n",
    "df.drop_duplicates(subset=cols_other_than_id, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e06b3354",
   "metadata": {},
   "outputs": [],
   "source": [
    "# identifies unique elements in your column\n",
    "candy.country.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb989d18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# script that removes space from entire data frame\n",
    "# Creating a function which will remove extra leading\n",
    "# and tailing whitespace from the data.\n",
    "# pass dataframe as a parameter here\n",
    "def whitespace_remover(df):\n",
    "   \n",
    "    # iterating over the columns\n",
    "    for i in df.columns:\n",
    "         \n",
    "        # checking datatype of each columns\n",
    "        if df[i].dtype == 'object':\n",
    "             \n",
    "            # applying strip function on column\n",
    "            df[i] = df[i].map(str.strip)\n",
    "        else:\n",
    "             \n",
    "            # if condn. is False then it will do nothing.\n",
    "            pass\n",
    " \n",
    "# applying whitespace_remover function on dataframe\n",
    "whitespace_remover(df)\n",
    " \n",
    "# printing dataframe\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5519ffe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# these functions will run through columns and delete special characters\n",
    "def pd_replace(df):\n",
    "    return df.assign(text=df['text'].str.replace(r'[^\\w\\s]+', ''))\n",
    "\n",
    "\n",
    "def re_sub(df):\n",
    "    p = re.compile(r'[^\\w\\s]+')\n",
    "    return df.assign(text=[p.sub('', x) for x in df['text'].tolist()])\n",
    "\n",
    "def translate(df):\n",
    "    punct = string.punctuation.replace('|', '')\n",
    "    transtab = str.maketrans(dict.fromkeys(punct, ''))\n",
    "\n",
    "    return df.assign(\n",
    "        text='|'.join(df['text'].tolist()).translate(transtab).split('|')\n",
    "    )\n",
    "\n",
    "# MaxU's version (https://stackoverflow.com/a/50444659/4909087)\n",
    "def pd_translate(df):\n",
    "    punct = string.punctuation.replace('|', '')\n",
    "    transtab = str.maketrans(dict.fromkeys(punct, ''))\n",
    "\n",
    "    return df.assign(text=df['text'].str.translate(transtab))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad1dac92",
   "metadata": {},
   "outputs": [],
   "source": [
    "# shape and data types of the data\n",
    "print(df.shape)\n",
    "print(df.dtypes)\n",
    "\n",
    "# select numeric columns\n",
    "df_numeric = df.select_dtypes(include=[np.number])\n",
    "numeric_cols = df_numeric.columns.values\n",
    "print(numeric_cols)\n",
    "\n",
    "# select non numeric columns\n",
    "df_non_numeric = df.select_dtypes(exclude=[np.number])\n",
    "non_numeric_cols = df_non_numeric.columns.values\n",
    "print(non_numeric_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fae98ce9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# missing data heatmap\n",
    "cols = df.columns[:30] # first 30 columns\n",
    "colours = ['#000099', '#ffff00'] # specify the colours - yellow is missing. blue is not missing.\n",
    "sns.heatmap(df[cols].isnull(), cmap=sns.color_palette(colours))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa401e85",
   "metadata": {},
   "outputs": [],
   "source": [
    "# missing data by percent\n",
    "# if it's a larger dataset and the visualization takes too long can do this.\n",
    "# % of missing.\n",
    "for col in df.columns:\n",
    "    pct_missing = np.mean(df[col].isnull())\n",
    "    print('{} - {}%'.format(col, round(pct_missing*100)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf392a35",
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop rows with a lot of missing values over 35\n",
    "ind_missing = df[df['num_missing'] > 35].index\n",
    "df_less_missing_rows = df.drop(ind_missing, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27c7c826",
   "metadata": {},
   "outputs": [],
   "source": [
    "# replace missing values with the median.\n",
    "med = df['life_sq'].median()\n",
    "print(med)\n",
    "df['life_sq'] = df['life_sq'].fillna(med)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5401dc93",
   "metadata": {},
   "outputs": [],
   "source": [
    "def impute(df, my_strategy, column_list):\n",
    "    ''' take in a df strategy and cloumn list\n",
    "        return df with listed columns imputed using input stratagy\n",
    "    '''\n",
    "        \n",
    "    imputer = SimpleImputer(strategy=my_strategy)  # build imputer\n",
    "\n",
    "    df[column_list] = imputer.fit_transform(df[column_list]) # fit/transform selected columns\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b5eb886",
   "metadata": {},
   "outputs": [],
   "source": [
    "# impute the missing values and create the missing value indicator variables for each numeric column.\n",
    "df_numeric = df.select_dtypes(include=[np.number])\n",
    "numeric_cols = df_numeric.columns.values\n",
    "\n",
    "for col in numeric_cols:\n",
    "    missing = df[col].isnull()\n",
    "    num_missing = np.sum(missing)\n",
    "    \n",
    "    if num_missing > 0:  # only do the imputation for the columns that have missing values.\n",
    "        print('imputing missing values for: {}'.format(col))\n",
    "        df['{}_ismissing'.format(col)] = missing\n",
    "        med = df[col].median()\n",
    "        df[col] = df[col].fillna(med)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ddf0248",
   "metadata": {},
   "outputs": [],
   "source": [
    "# impute the missing values and create the missing value indicator variables for each non-numeric column.\n",
    "df_non_numeric = df.select_dtypes(exclude=[np.number])\n",
    "non_numeric_cols = df_non_numeric.columns.values\n",
    "\n",
    "for col in non_numeric_cols:\n",
    "    missing = df[col].isnull()\n",
    "    num_missing = np.sum(missing)\n",
    "    \n",
    "    if num_missing > 0:  # only do the imputation for the columns that have missing values.\n",
    "        print('imputing missing values for: {}'.format(col))\n",
    "        df['{}_ismissing'.format(col)] = missing\n",
    "        \n",
    "        top = df[col].describe()['top'] # impute with the most frequent value.\n",
    "        df[col] = df[col].fillna(top)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9243e2ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# box plot for outliers\n",
    "df.boxplot(column=['life_sq'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f64649e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# statistics and identify outlier\n",
    "df['life_sq'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af3d7150",
   "metadata": {},
   "outputs": [],
   "source": [
    "# droppping dupes\n",
    "# we know that column 'id' is unique, but what if we drop it?\n",
    "df_dedupped = df.drop('id', axis=1).drop_duplicates()\n",
    "\n",
    "# there were duplicate rows\n",
    "print(df.shape)\n",
    "print(df_dedupped.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c6f07ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# make everything lower case.\n",
    "df['sub_area_lower'] = df['sub_area'].str.lower()\n",
    "df['sub_area_lower'].value_counts(dropna=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7065dec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# identifies the objects\n",
    "df.dtypes[df.dtypes != 'int64'][df.dtypes != 'float64']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "924b2f9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_outlier(df):\n",
    "    '''\n",
    "    This function will remove values that are 3 standard deviations above or below the mean for sqft, baths, beds, and tax_value.         (Our MVP values)\n",
    "    '''\n",
    "    new_df = df[(np.abs(stats.zscore(df['sqft'])) < 3)]\n",
    "    new_df = df[(np.abs(stats.zscore(df['baths'])) < 3)]\n",
    "    new_df = df[(np.abs(stats.zscore(df['beds'])) < 3)]\n",
    "    new_df = df[(np.abs(stats.zscore(df['tax_value'])) < 3)]\n",
    "    return new_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b71abef4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# scatter plot for outliers\n",
    "fig, ax = plt.subplots(figsize=(12,6))\n",
    "ax.scatter(df['Income'], df['Loan_amount'])\n",
    "ax.set_xlabel('Income of applicants in USD')\n",
    "ax.set_ylabel('Loan amount applied for in USD')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5825afc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# handling outliers\n",
    "def handle_outliers(df, col):\n",
    "    q1 = df[col].quantile(.25)\n",
    "    q3 = df[col].quantile(.75)\n",
    "    iqr = q3-q1 #Interquartile range\n",
    "    lower_bound  = q1-1.5*iqr\n",
    "    upper_bound = q3+1.5*iqr\n",
    "    if lower_bound < 0:\n",
    "        lower_bound = 0\n",
    "    if upper_bound > df[col].max():\n",
    "        upper_bound = df[col].max()\n",
    "    df_out = df.loc[(df[col] > lower_bound) & (df[col] < upper_bound)]\n",
    "    return df_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "808b9665",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from our acquire.py:\n",
    "def get_connection(db, user=env.user, host=env.host, password=env.password):\n",
    "    return f'mysql+pymysql://{user}:{password}@{host}/{db}'\n",
    "    \n",
    "def get_mallcustomer_data():\n",
    "    df = pd.read_sql('SELECT * FROM customers;', get_connection('mall_customers'))\n",
    "    return df.set_index('customer_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31c2735b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_connection(db, username=username, host=host, password=password):\n",
    "    '''\n",
    "    Creates a connection URL\n",
    "    '''\n",
    "    return f'mysql+pymysql://{username}:{password}@{host}/{db}'\n",
    "\n",
    "\n",
    "# connecting to sql db\n",
    "def new_zillow():\n",
    "    '''\n",
    "    Returns zillow into a dataframe\n",
    "    '''\n",
    "    sql_query = '''\n",
    "select *\n",
    "from properties_2017\n",
    "join (select parcelid, logerror, max(transactiondate) as transactiondate \n",
    "FROM predictions_2017 group by parcelid, logerror) as pred_2017 using(parcelid) \n",
    "left join airconditioningtype using(airconditioningtypeid)\n",
    "left join architecturalstyletype using(architecturalstyletypeid)\n",
    "left join buildingclasstype using(buildingclasstypeid)\n",
    "left join heatingorsystemtype using(heatingorsystemtypeid)\n",
    "left join propertylandusetype using(propertylandusetypeid)\n",
    "left join storytype using(storytypeid)\n",
    "left join typeconstructiontype using(typeconstructiontypeid)\n",
    "where properties_2017.latitude is not null\n",
    "and properties_2017.longitude is not null;\n",
    "'''\n",
    "    df = pd.read_sql(sql_query, get_connection('zillow'))\n",
    "    df.set_index('parcelid')\n",
    "    \n",
    "    #replace white space with nulls\n",
    "    df = df.replace(r'^\\s*$', np.nan, regex=True)\n",
    "    return df "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
<<<<<<< HEAD
   "id": "4393c750",
=======
   "id": "bb3fbf38",
>>>>>>> ed4649a11b800415de96dfa7ab51ed32118ab546
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sqlalchemy import create_engine\n",
    "# Postgres username, password, and database name\n",
    "POSTGRES_ADDRESS = 'db.panoply.io' ## INSERT YOUR DB ADDRESS IF IT'S NOT ON PANOPLY\n",
    "POSTGRES_PORT = '5439'\n",
    "POSTGRES_USERNAME = 'username' ## CHANGE THIS TO YOUR PANOPLY/POSTGRES USERNAME\n",
    "POSTGRES_PASSWORD = '*****' ## CHANGE THIS TO YOUR PANOPLY/POSTGRES PASSWORD POSTGRES_DBNAME = 'database' ## CHANGE THIS TO YOUR DATABASE NAME\n",
    "# A long string that contains the necessary Postgres login information\n",
    "postgres_str = ('postgresql://{username}:{password}@{ipaddress}:{port}/{dbname}'\n",
    "  .format(username=POSTGRES_USERNAME,\n",
    "   password=POSTGRES_PASSWORD,\n",
    "   ipaddress=POSTGRES_ADDRESS,\n",
    "   port=POSTGRES_PORT,\n",
    "   dbname=POSTGRES_DBNAME))\n",
    "# Create the connection\n",
    "cnx = create_engine(postgres_str)\n",
    "\n",
<<<<<<< HEAD
    "df = pd.read_sql_query('''SELECT * FROM pokemon LIMIT 5;''', cnx)\n",
=======
    "pd.read_sql_query('''SELECT * FROM pokemon LIMIT 5;''', cnx)\n",
>>>>>>> ed4649a11b800415de96dfa7ab51ed32118ab546
    "\n",
    "# how to connect to postgres db\n",
    "con = psycopg2.connect(\n",
    "    dbname=dn,\n",
    "    user=du,\n",
    "    password=dp,\n",
    "    host=dh,\n",
    "    port=dbp,\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
